{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VN1uRtOgR6ex"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import os\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Take All the ata into a list\n",
    "data_dir='C:\\\\Users\\\\MVI_lab_2\\\\Desktop\\\\piline\\\\dataset\\\\brain\\\\'\n",
    "image_dir='C:\\\\Users\\\\MVI_lab_2\\\\Desktop\\\\piline\\\\dataset\\\\ndbt\\\\'\n",
    "total_image=3064\n",
    "trainindata=[]\n",
    "for i in range(1,total_image+1):\n",
    "  filename=str(i)+\".mat\"\n",
    "  data=h5py.File(os.path.join(data_dir,filename),\"r\")\n",
    "  trainindata.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " # Now take all the image as train and test\n",
    "trainx=[]\n",
    "trainy=[]\n",
    "testx=[]\n",
    "testy=[]\n",
    "valx=[]\n",
    "valy=[]\n",
    "imx = []\n",
    "imy =[]\n",
    "imz =[]\n",
    "\n",
    "# For trainx and trainy\n",
    "for i in range(2451):\n",
    "  image=trainindata[i][\"cjdata\"][\"image\"][()]\n",
    "  if image.shape==(512,512):\n",
    "    imx.append(str(i+1))\n",
    "    label=int(trainindata[i][\"cjdata\"][\"label\"][()])-1\n",
    "    trainy.append(str(label))\n",
    "    \n",
    "# For trainx and trainy\n",
    "for i in range(2451,2757):\n",
    "  image=trainindata[i][\"cjdata\"][\"image\"][()]\n",
    "  if image.shape==(512,512):\n",
    "    imy.append(str(i+1))\n",
    "    label=int(trainindata[i][\"cjdata\"][\"label\"][()])-1\n",
    "    testy.append(str(label))\n",
    "\n",
    "for i in range(2757,total_image):\n",
    "  image=trainindata[i][\"cjdata\"][\"image\"][()]\n",
    "  if image.shape==(512,512):\n",
    "    imz.append(str(i+1))\n",
    "    label=int(trainindata[i][\"cjdata\"][\"label\"][()])-1\n",
    "    valy.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in imx:\n",
    "    im_name = i + \".jpg\"\n",
    "    im_path = os.path.join(image_dir,im_name)\n",
    "    trainx.append(im_path)\n",
    "\n",
    "# For trainx and trainy\n",
    "for i in imy:\n",
    "    im_name = i + \".jpg\"\n",
    "    im_path = os.path.join(image_dir,im_name)\n",
    "    testx.append(im_path)\n",
    "\n",
    "for i in imz:\n",
    "    im_name = i + \".jpg\"\n",
    "    im_path = os.path.join(image_dir,im_name)\n",
    "    valx.append(im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2436 2436\n"
     ]
    }
   ],
   "source": [
    "print(len(trainx),len(trainy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {'image': trainx, 'label': trainy}\n",
    "train_df = pd.DataFrame(train_dict)\n",
    "test_dict = {'image': testx, 'label': testy}\n",
    "test_df = pd.DataFrame(test_dict)\n",
    "val_dict = {'image': valx, 'label': valy}\n",
    "val_df = pd.DataFrame(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = pd.concat([train_df, test_df, val_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df length:  2439  test_df length:  305   valid_df length:  305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_split=.8\n",
    "test_split=.1\n",
    "dummy_split=test_split/(1-train_split)\n",
    "train_df, dummy_df=train_test_split(t_df, train_size=train_split, shuffle=True, random_state=123)\n",
    "test_df, val_df=train_test_split(dummy_df, train_size=dummy_split, shuffle=True, random_state=123)\n",
    "print ('train_df length: ', len(train_df), ' test_df length: ', len(test_df), '  valid_df length: ', len(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2439 validated image filenames belonging to 3 classes.\n",
      "Found 305 validated image filenames belonging to 3 classes.\n",
      "Found 305 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "height=512\n",
    "width=512\n",
    "channels=3\n",
    "batch_size=32\n",
    "img_shape=(height, width, channels)\n",
    "img_size=(height, width)\n",
    "def scalar(img):\n",
    "    return img/127.5-1  # scale pixel between -1 and +1\n",
    "gen=ImageDataGenerator(preprocessing_function=scalar)\n",
    "train_gen = gen.flow_from_dataframe(train_df, x_col='image', y_col='label', target_size=img_size, class_mode='categorical',\n",
    "                                    color_mode='grayscale', shuffle=True, batch_size=batch_size)\n",
    "test_gen = gen.flow_from_dataframe(test_df, x_col='image', y_col='label', target_size=img_size, class_mode='categorical',\n",
    "                                    color_mode='grayscale', shuffle=True, batch_size=batch_size)\n",
    "val_gen = gen.flow_from_dataframe(val_df, x_col='image', y_col='label', target_size=img_size, class_mode='categorical',\n",
    "                                    color_mode='grayscale', shuffle=True, batch_size=batch_size)\n",
    "classes=list(train_gen.class_indices.keys())\n",
    "class_count=len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 1.6162464985994398, 1: 1.0, 0: 2.021015761821366}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter = Counter(train_gen.classes)\n",
    "max_val = float(max(counter.values()))\n",
    "class_weights = {class_id : max_val/num_images for class_id, num_images in counter.items()}\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model building starts\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import numpy as np\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Initial  BLock of the model\n",
    "ini_input=keras.Input(shape=(512,512,1),name=\"image\")\n",
    "\n",
    "x1=layers.Conv2D(64,(22,22),strides=2)(ini_input)\n",
    "x1=layers.MaxPooling2D((4,4))(x1)\n",
    "x1=layers.BatchNormalization()(x1)\n",
    "\n",
    "x2=layers.Conv2D(128,(11,11),strides=2,padding=\"same\")(x1)\n",
    "x2=layers.MaxPooling2D((2,2))(x2)\n",
    "x2=layers.BatchNormalization()(x2)\n",
    "\n",
    "x3=layers.GlobalAveragePooling2D()(x2)\n",
    "x3=layers.Activation(\"relu\")(x3)\n",
    "\n",
    "x4=layers.Dense(512,\"relu\")(x3)\n",
    "x4=layers.BatchNormalization()(x4)\n",
    "x5=layers.Dense(256,\"relu\")(x4)\n",
    "x5=layers.BatchNormalization()(x5)\n",
    "x5=layers.Dropout(.2)(x5)\n",
    "x6=layers.Dense(3)(x5)\n",
    "pred=layers.Activation(\"softmax\")(x6)\n",
    "\n",
    "model=keras.Model(inputs=ini_input,outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image (InputLayer)          [(None, 512, 512, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 246, 246, 64)      31040     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 61, 61, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 61, 61, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 31, 31, 128)       991360    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 15, 15, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 15, 15, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 256)         1605888   \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 4, 4, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 1, 1, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1, 1, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " activation (Activation)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              525312    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 771       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,001,667\n",
      "Trainable params: 4,996,163\n",
      "Non-trainable params: 5,504\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "for x, y in train_gen:\n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "\n",
    "x_test = []\n",
    "y_test = []\n",
    "for x, y in train_gen:\n",
    "    x_test.append(x)\n",
    "    y_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=model.fit(x_train,\n",
    "            y_train,\n",
    "          epochs=100,\n",
    "          batch_size=32,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          shuffle=False\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
